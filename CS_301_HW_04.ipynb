{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Birju Dhaduk\n",
    "# Date: 20200223\n",
    "# CS301-006, Professor Watson\n",
    "# HW04 Solution\n",
    "# Solve for various values based on the dataframe regarding the corona virus\n",
    "# https://github.com/birjudhaduk/cs301\n",
    "# https://github.com/birjudhaduk/cs301/commit/84896d0f2e184749ee26a7f8a84c7be8dee37134\n",
    "# master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 301 HW 04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_percent_nans(df, column_name):\n",
    "    num_rows = df.shape[0]\n",
    "    num_filled = df[col].count()\n",
    "    percent_nans = (num_rows - num_filled) / num_rows * 100\n",
    "    return percent_nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The \"Province/State\" column has 24.45% empty values\n",
      "The \"Country/Region\" column has 0.00% empty values\n",
      "The \"Last Update\" column has 0.00% empty values\n",
      "The \"Confirmed\" column has 1.60% empty values\n",
      "The \"Suspected\" column has 95.31% empty values\n",
      "The \"Recovered\" column has 46.67% empty values\n",
      "The \"Death\" column has 53.22% empty values\n"
     ]
    }
   ],
   "source": [
    "cv_df = pd.read_csv('C:\\\\Users\\\\birju\\\\Documents\\\\CS 301\\\\2019-coronavirus-dataset-01212020-01262020\\\\2019_nCoV_20200121_20200206.csv')\n",
    "for col in cv_df.columns:\n",
    "    print('The \\\"{}\\\" column has {:.2f}% empty values'.format(col, get_percent_nans(cv_df, col)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The country/region with the most deaths is Mainland China\n"
     ]
    }
   ],
   "source": [
    "max_deaths = 0\n",
    "for val in cv_df['Country/Region'].unique():\n",
    "    num = (cv_df.loc[(cv_df['Country/Region'] == val)])['Death'].count()\n",
    "    if num > max_deaths:\n",
    "        country_w_max = val\n",
    "        max_deaths = num\n",
    "print('The country/region with the most deaths is {}'.format(country_w_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The country/region with the most suspected cases is Mainland China\n"
     ]
    }
   ],
   "source": [
    "max_suspects = 0\n",
    "for val in cv_df['Country/Region'].unique():\n",
    "    num = (cv_df.loc[(cv_df['Country/Region'] == val)])['Suspected'].count()\n",
    "    if num > max_suspects:\n",
    "        country_w_max = val\n",
    "        max_suspects = num\n",
    "print('The country/region with the most suspected cases is {}'.format(country_w_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The country/region with the second most recovered cases is United States\n"
     ]
    }
   ],
   "source": [
    "max_recovered = 0\n",
    "for val in cv_df['Country/Region'].unique():\n",
    "    num = (cv_df.loc[(cv_df['Country/Region'] == val)])['Recovered'].count()\n",
    "    if num > max_recovered:\n",
    "        country_w_max = val\n",
    "        max_recovered = num\n",
    "second_max_recovered = 0\n",
    "for val in cv_df['Country/Region'].unique():\n",
    "    num = (cv_df.loc[(cv_df['Country/Region'] == val)])['Recovered'].count()\n",
    "    if num > second_max_recovered and num < max_recovered:\n",
    "        country_w_second_max = val\n",
    "        second_max_recovered = num\n",
    "print('The country/region with the second most recovered cases is {}'.format(country_w_second_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Mainland China': 'Asia', 'Singapore': 'Asia', 'Thailand': 'Asia', 'Japan': 'Asia', 'Hong Kong': 'Asia', 'South Korea': 'Asia', 'Germany': 'Europe', 'Malaysia': 'Asia', 'Taiwan': 'Asia', 'Macau': 'Asia', 'Vietnam': 'Asia', 'France': 'Europe', 'United Arab Emirates': 'Asia', 'Australia': 'Oceania', 'India': 'Asia', 'Canada': 'North America', 'Italy': 'Europe', 'Philippines': 'Asia', 'Russia': 'Asia and Europe', 'UK': 'Europe', 'United States': 'North America', 'Belgium': 'Europe', 'Cambodia': 'Asia', 'Finland': 'Europe', 'Nepal': 'Asia', 'Spain': 'Europe', 'Sri Lanka': 'Asia', 'Sweden': 'Europe', 'Ivory Coast': 'Africa', 'Mexico': 'North America', 'Brazil': 'South America', 'Colombia': 'South America'}\n"
     ]
    }
   ],
   "source": [
    "country_to_continent = {}\n",
    "for each in cv_df['Country/Region'].unique():\n",
    "    if each == 'Mainland China' or each == 'Sri Lanka' or each == 'Nepal' or each == 'Cambodia' or each == 'Philippines' or each == 'Singapore' or each == 'India' or each == 'Thailand' or each == 'Japan' or each == 'Hong Kong' or each == 'South Korea' or each == 'Malaysia' or each == 'Taiwan' or each == 'Macau' or each == 'Vietnam' or each == 'United Arab Emirates':\n",
    "        country_to_continent[each] = 'Asia'\n",
    "    if each == 'Germany' or each == 'Finland' or each == 'Sweden' or each == 'Spain' or each == 'Europe' or each == 'UK' or each == 'Belgium' or each == 'Italy' or each == 'France':\n",
    "        country_to_continent[each] = 'Europe'\n",
    "    if each == 'Australia':\n",
    "        country_to_continent[each] = 'Oceania'\n",
    "    if each == 'Canada' or each == 'Mexico' or each == 'United States':\n",
    "        country_to_continent[each] = 'North America'\n",
    "    if each == 'Russia':\n",
    "        country_to_continent[each] = 'Asia and Europe'\n",
    "    if each == 'Ivory Coast':\n",
    "        country_to_continent[each] = 'Africa'\n",
    "    if each == 'Brazil' or each == 'Colombia':\n",
    "        country_to_continent[each] = 'South America'\n",
    "print(country_to_continent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_continent(country):\n",
    "    country_to_continent = {}\n",
    "    for each in cv_df['Country/Region'].unique():\n",
    "        if each == 'Mainland China' or each == 'Sri Lanka' or each == 'Nepal' or each == 'Cambodia' or each == 'Philippines' or each == 'Singapore' or each == 'India' or each == 'Thailand' or each == 'Japan' or each == 'Hong Kong' or each == 'South Korea' or each == 'Malaysia' or each == 'Taiwan' or each == 'Macau' or each == 'Vietnam' or each == 'United Arab Emirates':\n",
    "            country_to_continent[each] = 'Asia'\n",
    "        if each == 'Germany' or each == 'Sweden' or each == 'Spain' or each == 'Europe' or each == 'UK' or each == 'Belgium' or each == 'Italy' or each == 'France':\n",
    "            country_to_continent[each] = 'Europe'\n",
    "        if each == 'Australia':\n",
    "            country_to_continent[each] = 'Oceania'\n",
    "        if each == 'Canada' or each == 'Mexico' or each == 'United States':\n",
    "            country_to_continent[each] = 'North America'\n",
    "        if each == 'Russia':\n",
    "            country_to_continent[each] = 'Asia and Europe'\n",
    "        if each == 'Ivory Coast':\n",
    "            country_to_continent[each] = 'Africa'\n",
    "        if each == 'Brazil' or each == 'Colombia':\n",
    "            country_to_continent[each] = 'South America'\n",
    "    return country_to_continent[country]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Europe'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_continent('UK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Last Update</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Suspected</th>\n",
       "      <th>Recovered</th>\n",
       "      <th>Death</th>\n",
       "      <th>Continent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Hubei</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>2/5/20 16:43</td>\n",
       "      <td>16678.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>538.0</td>\n",
       "      <td>479.0</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Guangdong</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>2/5/20 13:23</td>\n",
       "      <td>895.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Zhejiang</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>2/5/20 15:13</td>\n",
       "      <td>895.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Henan</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>2/5/20 15:03</td>\n",
       "      <td>764.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Hunan</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>2/5/20 15:23</td>\n",
       "      <td>661.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1872</td>\n",
       "      <td>Heilongjiang</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1/21/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Japan</td>\n",
       "      <td>1/21/2020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1874</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>1/21/2020</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>1/21/2020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1876</td>\n",
       "      <td>Washington</td>\n",
       "      <td>United States</td>\n",
       "      <td>1/21/2020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1877 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Province/State  Country/Region   Last Update  Confirmed  Suspected  \\\n",
       "0             Hubei  Mainland China  2/5/20 16:43    16678.0        NaN   \n",
       "1         Guangdong  Mainland China  2/5/20 13:23      895.0        NaN   \n",
       "2          Zhejiang  Mainland China  2/5/20 15:13      895.0        NaN   \n",
       "3             Henan  Mainland China  2/5/20 15:03      764.0        NaN   \n",
       "4             Hunan  Mainland China  2/5/20 15:23      661.0        NaN   \n",
       "...             ...             ...           ...        ...        ...   \n",
       "1872   Heilongjiang  Mainland China     1/21/2020        NaN        1.0   \n",
       "1873            NaN           Japan     1/21/2020        1.0        NaN   \n",
       "1874            NaN        Thailand     1/21/2020        2.0        NaN   \n",
       "1875            NaN     South Korea     1/21/2020        1.0        NaN   \n",
       "1876     Washington   United States     1/21/2020        1.0        NaN   \n",
       "\n",
       "      Recovered  Death      Continent  \n",
       "0         538.0  479.0           Asia  \n",
       "1          49.0    0.0           Asia  \n",
       "2          78.0    0.0           Asia  \n",
       "3          47.0    2.0           Asia  \n",
       "4          54.0    0.0           Asia  \n",
       "...         ...    ...            ...  \n",
       "1872        NaN    NaN           Asia  \n",
       "1873        NaN    NaN           Asia  \n",
       "1874        NaN    NaN           Asia  \n",
       "1875        NaN    NaN           Asia  \n",
       "1876        NaN    NaN  North America  \n",
       "\n",
       "[1877 rows x 8 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for each in cv_df['Country/Region']:\n",
    "    cv_df.loc[(cv_df['Country/Region'] == each), 'Continent'] = country_to_continent[each]\n",
    "cv_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asia has 1425 confirmed cases\n",
      "Europe has 124 confirmed cases\n",
      "Oceania has 80 confirmed cases\n",
      "North America has 204 confirmed cases\n",
      "Asia and Europe has 13 confirmed cases\n",
      "Africa has 1 confirmed cases\n",
      "South America has 0 confirmed cases\n"
     ]
    }
   ],
   "source": [
    "for each in cv_df['Continent'].unique():\n",
    "    count = (cv_df.loc[(cv_df['Continent'] == each)])['Confirmed'].count()\n",
    "    print(each, end = ' ')\n",
    "    print('has {} confirmed cases'.format(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
